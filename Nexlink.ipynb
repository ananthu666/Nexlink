{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx1LopnTCc2qEaWGfmcH5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananthu666/Nexlink/blob/main/Nexlink.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrd7dZFpwEWT",
        "outputId": "f952f120-750a-44d5-a78c-80e578233a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "import torch_geometric\n",
        "print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "T1hE_NXrwmY8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the Cora dataset\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.10, num_test=0.20, neg_sampling_ratio = 1.0,\n",
        "                  is_undirected=True, add_negative_train_samples=False),\n",
        "])\n",
        "dataset = Planetoid('./data/Planetoid', name='Cora', transform=transform)\n",
        "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
        "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
        "# each element representing the corresponding split.\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "print(train_data)\n",
        "print(val_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsvwRHspwwnt",
        "outputId": "633f9784-158e-4fc8-8445-93bfb11d146c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2708, 1433], edge_index=[2, 7392], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[3696], edge_label_index=[2, 3696])\n",
            "Data(x=[2708, 1433], edge_index=[2, 7392], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[1054], edge_label_index=[2, 1054])\n",
            "Data(x=[2708, 1433], edge_index=[2, 8446], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[2110], edge_label_index=[2, 2110])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data.edge_index[0] <= train_data.edge_index[1]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSNM-6JIw18I",
        "outputId": "091a8d09-6b24-45ab-d204-317b0007f7aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3696)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        #return the indices of a non-zero element\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
      ],
      "metadata": {
        "id": "QI2NqhdBw8Ht"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(dataset.num_features, 128, 64).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "KLmUC2rUw8kt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "    # We perform a new round of negative sampling for every training epoch:\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "        num_neg_samples=train_data.edge_label_index.size(1))\n",
        "\n",
        "    edge_label_index = torch.cat(\n",
        "        [train_data.edge_label_index, neg_edge_index],\n",
        "        dim=-1,\n",
        "    )\n",
        "    edge_label = torch.cat([\n",
        "        train_data.edge_label,\n",
        "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "    ], dim=0)\n",
        "\n",
        "    out = model.decode(z, edge_label_index).view(-1)\n",
        "    loss = criterion(out, edge_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "6TsKtwsuxErH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_auc = final_test_auc = 0\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    val_auc = test(val_data)\n",
        "    test_auc = test(test_data)\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val = val_auc\n",
        "        final_test_auc = test_auc\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
        "          f'Test: {test_auc:.4f}')\n",
        "\n",
        "print(f'Final Test: {final_test_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H00RBJOoxH5a",
        "outputId": "044168bb-98c6-465e-8536-6bac1a87ad64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.4279, Val: 0.9069, Test: 0.9097\n",
            "Epoch: 002, Loss: 0.4319, Val: 0.9072, Test: 0.9098\n",
            "Epoch: 003, Loss: 0.4293, Val: 0.9069, Test: 0.9096\n",
            "Epoch: 004, Loss: 0.4333, Val: 0.9072, Test: 0.9104\n",
            "Epoch: 005, Loss: 0.4285, Val: 0.9077, Test: 0.9107\n",
            "Epoch: 006, Loss: 0.4220, Val: 0.9075, Test: 0.9097\n",
            "Epoch: 007, Loss: 0.4245, Val: 0.9078, Test: 0.9095\n",
            "Epoch: 008, Loss: 0.4267, Val: 0.9079, Test: 0.9093\n",
            "Epoch: 009, Loss: 0.4188, Val: 0.9076, Test: 0.9091\n",
            "Epoch: 010, Loss: 0.4252, Val: 0.9077, Test: 0.9100\n",
            "Epoch: 011, Loss: 0.4212, Val: 0.9082, Test: 0.9103\n",
            "Epoch: 012, Loss: 0.4232, Val: 0.9090, Test: 0.9102\n",
            "Epoch: 013, Loss: 0.4220, Val: 0.9097, Test: 0.9104\n",
            "Epoch: 014, Loss: 0.4241, Val: 0.9090, Test: 0.9101\n",
            "Epoch: 015, Loss: 0.4299, Val: 0.9077, Test: 0.9093\n",
            "Epoch: 016, Loss: 0.4239, Val: 0.9085, Test: 0.9097\n",
            "Epoch: 017, Loss: 0.4190, Val: 0.9098, Test: 0.9095\n",
            "Epoch: 018, Loss: 0.4198, Val: 0.9096, Test: 0.9095\n",
            "Epoch: 019, Loss: 0.4137, Val: 0.9101, Test: 0.9106\n",
            "Epoch: 020, Loss: 0.4171, Val: 0.9099, Test: 0.9108\n",
            "Epoch: 021, Loss: 0.4195, Val: 0.9098, Test: 0.9095\n",
            "Epoch: 022, Loss: 0.4147, Val: 0.9107, Test: 0.9084\n",
            "Epoch: 023, Loss: 0.4229, Val: 0.9105, Test: 0.9082\n",
            "Epoch: 024, Loss: 0.4174, Val: 0.9114, Test: 0.9098\n",
            "Epoch: 025, Loss: 0.4206, Val: 0.9123, Test: 0.9105\n",
            "Epoch: 026, Loss: 0.4195, Val: 0.9129, Test: 0.9096\n",
            "Epoch: 027, Loss: 0.4195, Val: 0.9119, Test: 0.9074\n",
            "Epoch: 028, Loss: 0.4199, Val: 0.9109, Test: 0.9068\n",
            "Epoch: 029, Loss: 0.4138, Val: 0.9109, Test: 0.9083\n",
            "Epoch: 030, Loss: 0.4202, Val: 0.9125, Test: 0.9097\n",
            "Epoch: 031, Loss: 0.4223, Val: 0.9114, Test: 0.9084\n",
            "Epoch: 032, Loss: 0.4223, Val: 0.9099, Test: 0.9064\n",
            "Epoch: 033, Loss: 0.4246, Val: 0.9095, Test: 0.9061\n",
            "Epoch: 034, Loss: 0.4200, Val: 0.9096, Test: 0.9063\n",
            "Epoch: 035, Loss: 0.4180, Val: 0.9096, Test: 0.9060\n",
            "Epoch: 036, Loss: 0.4154, Val: 0.9090, Test: 0.9057\n",
            "Epoch: 037, Loss: 0.4131, Val: 0.9103, Test: 0.9067\n",
            "Epoch: 038, Loss: 0.4194, Val: 0.9101, Test: 0.9069\n",
            "Epoch: 039, Loss: 0.4101, Val: 0.9095, Test: 0.9069\n",
            "Epoch: 040, Loss: 0.4146, Val: 0.9075, Test: 0.9064\n",
            "Epoch: 041, Loss: 0.4218, Val: 0.9068, Test: 0.9063\n",
            "Epoch: 042, Loss: 0.4144, Val: 0.9096, Test: 0.9077\n",
            "Epoch: 043, Loss: 0.4193, Val: 0.9116, Test: 0.9087\n",
            "Epoch: 044, Loss: 0.4141, Val: 0.9115, Test: 0.9088\n",
            "Epoch: 045, Loss: 0.4101, Val: 0.9100, Test: 0.9087\n",
            "Epoch: 046, Loss: 0.4153, Val: 0.9083, Test: 0.9075\n",
            "Epoch: 047, Loss: 0.4148, Val: 0.9088, Test: 0.9067\n",
            "Epoch: 048, Loss: 0.4233, Val: 0.9108, Test: 0.9086\n",
            "Epoch: 049, Loss: 0.4129, Val: 0.9122, Test: 0.9097\n",
            "Epoch: 050, Loss: 0.4153, Val: 0.9121, Test: 0.9091\n",
            "Epoch: 051, Loss: 0.4178, Val: 0.9108, Test: 0.9079\n",
            "Epoch: 052, Loss: 0.4148, Val: 0.9102, Test: 0.9063\n",
            "Epoch: 053, Loss: 0.4144, Val: 0.9102, Test: 0.9065\n",
            "Epoch: 054, Loss: 0.4137, Val: 0.9108, Test: 0.9079\n",
            "Epoch: 055, Loss: 0.4163, Val: 0.9108, Test: 0.9092\n",
            "Epoch: 056, Loss: 0.4094, Val: 0.9104, Test: 0.9087\n",
            "Epoch: 057, Loss: 0.4132, Val: 0.9101, Test: 0.9076\n",
            "Epoch: 058, Loss: 0.4093, Val: 0.9095, Test: 0.9065\n",
            "Epoch: 059, Loss: 0.4107, Val: 0.9090, Test: 0.9059\n",
            "Epoch: 060, Loss: 0.4194, Val: 0.9088, Test: 0.9070\n",
            "Epoch: 061, Loss: 0.4124, Val: 0.9089, Test: 0.9081\n",
            "Epoch: 062, Loss: 0.4131, Val: 0.9093, Test: 0.9083\n",
            "Epoch: 063, Loss: 0.4171, Val: 0.9086, Test: 0.9075\n",
            "Epoch: 064, Loss: 0.4140, Val: 0.9080, Test: 0.9063\n",
            "Epoch: 065, Loss: 0.4180, Val: 0.9071, Test: 0.9052\n",
            "Epoch: 066, Loss: 0.4113, Val: 0.9072, Test: 0.9053\n",
            "Epoch: 067, Loss: 0.4132, Val: 0.9072, Test: 0.9063\n",
            "Epoch: 068, Loss: 0.4165, Val: 0.9066, Test: 0.9070\n",
            "Epoch: 069, Loss: 0.4108, Val: 0.9063, Test: 0.9065\n",
            "Epoch: 070, Loss: 0.4129, Val: 0.9074, Test: 0.9063\n",
            "Epoch: 071, Loss: 0.4103, Val: 0.9082, Test: 0.9066\n",
            "Epoch: 072, Loss: 0.4148, Val: 0.9071, Test: 0.9071\n",
            "Epoch: 073, Loss: 0.4078, Val: 0.9054, Test: 0.9067\n",
            "Epoch: 074, Loss: 0.4168, Val: 0.9047, Test: 0.9068\n",
            "Epoch: 075, Loss: 0.4188, Val: 0.9043, Test: 0.9067\n",
            "Epoch: 076, Loss: 0.4110, Val: 0.9050, Test: 0.9079\n",
            "Epoch: 077, Loss: 0.4108, Val: 0.9055, Test: 0.9094\n",
            "Epoch: 078, Loss: 0.4090, Val: 0.9050, Test: 0.9090\n",
            "Epoch: 079, Loss: 0.4203, Val: 0.9031, Test: 0.9073\n",
            "Epoch: 080, Loss: 0.4125, Val: 0.9017, Test: 0.9074\n",
            "Epoch: 081, Loss: 0.4091, Val: 0.9018, Test: 0.9086\n",
            "Epoch: 082, Loss: 0.4079, Val: 0.9028, Test: 0.9090\n",
            "Epoch: 083, Loss: 0.4165, Val: 0.9030, Test: 0.9081\n",
            "Epoch: 084, Loss: 0.4122, Val: 0.9021, Test: 0.9075\n",
            "Epoch: 085, Loss: 0.4053, Val: 0.9014, Test: 0.9070\n",
            "Epoch: 086, Loss: 0.4145, Val: 0.9011, Test: 0.9081\n",
            "Epoch: 087, Loss: 0.4072, Val: 0.9023, Test: 0.9089\n",
            "Epoch: 088, Loss: 0.4108, Val: 0.9052, Test: 0.9084\n",
            "Epoch: 089, Loss: 0.4117, Val: 0.9059, Test: 0.9075\n",
            "Epoch: 090, Loss: 0.4160, Val: 0.9037, Test: 0.9069\n",
            "Epoch: 091, Loss: 0.4111, Val: 0.9011, Test: 0.9074\n",
            "Epoch: 092, Loss: 0.4131, Val: 0.9003, Test: 0.9077\n",
            "Epoch: 093, Loss: 0.4168, Val: 0.9016, Test: 0.9086\n",
            "Epoch: 094, Loss: 0.4134, Val: 0.9025, Test: 0.9083\n",
            "Epoch: 095, Loss: 0.4098, Val: 0.9017, Test: 0.9067\n",
            "Epoch: 096, Loss: 0.4047, Val: 0.8989, Test: 0.9063\n",
            "Epoch: 097, Loss: 0.4046, Val: 0.8981, Test: 0.9070\n",
            "Epoch: 098, Loss: 0.4091, Val: 0.8988, Test: 0.9075\n",
            "Epoch: 099, Loss: 0.4087, Val: 0.8992, Test: 0.9072\n",
            "Epoch: 100, Loss: 0.4074, Val: 0.8985, Test: 0.9063\n",
            "Final Test: 0.9063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = model.encode(test_data.x, test_data.edge_index)\n",
        "final_edge_index = model.decode_all(z)"
      ],
      "metadata": {
        "id": "VGs9VhhOxeO0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC3ACUmSxf5K",
        "outputId": "27298837-bd96-4bf4-8366-5496d6a08f54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
              "        [   0,    1,    2,  ..., 2705, 2706, 2707]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2R8WjUkwxhbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}